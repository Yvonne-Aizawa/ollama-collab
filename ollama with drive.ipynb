{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ollama colab book"
      ],
      "metadata": {
        "id": "TmFINXz-sq49"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "download/install stuff"
      ],
      "metadata": {
        "id": "WI4cOFFJtAF4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EStRDLaaslo0"
      },
      "outputs": [],
      "source": [
        "!curl -L https://ollama.ai/download/ollama-linux-amd64 -o ollama\n",
        "!chmod +x ./ollama\n",
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "open up a tunnel"
      ],
      "metadata": {
        "id": "iW7_9Ux5tLEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Open a HTTP tunnel on the default port 80\n",
        "# <NgrokTunnel: \"https://<public_sub>.ngrok.io\" -> \"http://localhost:80\">\n",
        "http_tunnel = ngrok.connect(\"11434\")\n",
        "print(http_tunnel)"
      ],
      "metadata": {
        "id": "0djqWO5xtDr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "connect drive and configure ollama to load models from there"
      ],
      "metadata": {
        "id": "gBisuzV1C-rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# This line mounts your Google Drive to the path '/content/drive'\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the models_path\n",
        "models_path = '/content/drive/MyDrive/ollama/models'\n",
        "\n",
        "# Set the 'OLLAMA_MODELS' environment variable to the models_path\n",
        "os.environ['OLLAMA_MODELS'] = models_path"
      ],
      "metadata": {
        "id": "JwHqpFVW4L0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "serve ollama"
      ],
      "metadata": {
        "id": "fePylmAytdgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x /content/ollama\n",
        "!/content/ollama serve"
      ],
      "metadata": {
        "id": "-KlQi1rstdMD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}